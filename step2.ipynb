{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "step2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enixes/HackBMU/blob/master/step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NwvnPiaUVJgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "from os import listdir, environ\n",
        "from os.path import isfile, join\n",
        "\n",
        "# to allocate only one GPU for this notebook (I have two on board)\n",
        "# environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "from xgboost import XGBClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZyph91kVJgy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ResNet50 model"
      ]
    },
    {
      "metadata": {
        "id": "kwR5U6VEVJg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive_img_path =  \"./datasets/positive/\"  # where to find positive examples (images with amber extraction footprints ) \n",
        "negative_img_path =  \"./datasets/negative/\"  # where to find negative examples \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bj-KjeFYVJhC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list of positive and negative filenames\n",
        "positive_files = [join(positive_img_path, f) for f in listdir(positive_img_path) if isfile(join(positive_img_path, f))] # list of image names with positive examples\n",
        "negative_files = [join(negative_img_path, f) for f in listdir(negative_img_path) if isfile(join(negative_img_path, f))] # list of image names with negative examples\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False) # load ResNet50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrFiwG57VJhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "q1ItVwSnVJhL",
        "colab_type": "code",
        "colab": {},
        "outputId": "ca75b688-ecfc-409f-9904-eb4b6bd7212a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_features(img_paths, batch_size=64):\n",
        "    \"\"\" This function extracts image features for each image in img_paths using ResNet50 penultimate layer.\n",
        "        Returned features is a numpy array with shape (len(img_paths), 2048).\n",
        "    \"\"\"\n",
        "    global resnet\n",
        "    n = len(img_paths) # num of images in img_paths\n",
        "    img_array = np.zeros((n, 224, 224, 3))\n",
        "    \n",
        "    for i, path in enumerate(img_paths):\n",
        "        img = image.load_img(path, target_size=(224, 224))  # load and scale each image to 224x224 size\n",
        "        img = image.img_to_array(img)\n",
        "        img = preprocess_input(img)\n",
        "        img_array[i] = img\n",
        "    \n",
        "    X = resnet.predict(img_array, batch_size=batch_size, verbose=1)\n",
        "    X = X.reshape((n, 2048))\n",
        "    return X\n",
        "\n",
        "# features for our two types of labels\n",
        "positives_ = extract_features(positive_files)\n",
        "negatives_ = extract_features(negative_files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 5s 22ms/step\n",
            "900/900 [==============================] - 13s 15ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VugaliHfVJhY",
        "colab_type": "code",
        "colab": {},
        "outputId": "9ec0a160-97fd-438b-bf3b-9c2451bec7b4"
      },
      "cell_type": "code",
      "source": [
        "# Create dataframe from two types of features, for positive images(with amber mining footprints) and \n",
        "# negative(without mining) \n",
        "\n",
        "def create_df(feature_vectors, label, img_paths):\n",
        "    \"\"\" create panda df. Each row in df consists of features, label and path to corresponding image \"\"\"\n",
        "    feat_cols = [ 'feature'+str(i) for i in range(feature_vectors.shape[1]) ] # column names for elements of feature vector\n",
        "    df = pd.DataFrame(feature_vectors,columns=feat_cols)\n",
        "    df['label'] = label # add column with labels\n",
        "    df['path'] = img_paths # add column with img paths\n",
        "    return df\n",
        "\n",
        "df1 = create_df(positives_, \"positive\", positive_files)\n",
        "df2 = create_df(negatives_, \"negative\", negative_files)\n",
        "df = df1.append(df2)\n",
        "print 'Size of the dataframe: {}'.format(df.shape)\n",
        "\n",
        "# in case you want to save features for later use, uncomment line below\n",
        "# df.to_csv(\"features_backup.csv\",  index = False) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the dataframe: (1150, 2050)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u6RW-Ln_VJhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### IGNORE this cell if you successfully run all cells above.\n",
        "\n",
        "### START HERE if you don't want to calculate features from images: instead, get it from backup\n",
        "df = pd.read_csv(\"features_backup.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UwV7RC9nVJh1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:2048].values  # numeric feature values for each image\n",
        "Y = df.iloc[:, 2048].values   # labels for each image\n",
        "tiles = df[\"path\"].values     # path to image files \n",
        "\n",
        "# split each list to test and train parts \n",
        "X_train, X_test, Y_train, Y_test, tiles_train, tiles_test = train_test_split(X, Y, tiles, test_size = 0.3, \n",
        "                                                                             random_state = 43)\n",
        "\n",
        "# Just print all evaluation scores from one place\n",
        "def evaluate(Y_test, Y_pred):\n",
        "    accuracy = accuracy_score(Y_test, Y_pred)\n",
        "    print(\"\\nModel Performance\")\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    print(confusion_matrix(Y_test, Y_pred))\n",
        "    print(\"\\nprecision:\")\n",
        "    print(precision_score(Y_test, Y_pred, pos_label = \"positive\"))\n",
        "    print(\"\\nrecall:\")\n",
        "    print(recall_score(Y_test, Y_pred, pos_label = \"positive\"))\n",
        "    print(\"\\nf1:\")\n",
        "    print(f1_score(Y_test, Y_pred, pos_label = \"positive\") ) \n",
        "    return accuracy\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vjKrQYyoVJiH",
        "colab_type": "code",
        "colab": {},
        "outputId": "ac19854f-01f6-4970-868b-5c794ded38ee"
      },
      "cell_type": "code",
      "source": [
        "# TODO: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
        "\n",
        "\n",
        "clf = XGBClassifier( learning_rate =0.01,\n",
        "                     n_estimators=5000,\n",
        "                     max_depth=4,\n",
        "                     min_child_weight=6,\n",
        "                     gamma=0,\n",
        "                     subsample=0.8,\n",
        "                     colsample_bytree=0.8,\n",
        "                     reg_alpha=0.005,\n",
        "                     objective= 'binary:logistic',\n",
        "                     nthread=7,\n",
        "                     scale_pos_weight=1,seed=27\n",
        "                   )\n",
        "\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "# to save a model, uncomment this\n",
        "# joblib.dump(clf, 'versions/xgb_model.pkl')\n",
        "\n",
        "# you can load actual production model from this file, uncomment line below:\n",
        "# clf = joblib.load( 'versions/xgb_model_v003.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['versions/xgb_model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "H-lrbXZ5VJiQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "metadata": {
        "id": "1D2yWY8YVJiU",
        "colab_type": "code",
        "colab": {},
        "outputId": "7c6f8664-23b6-405f-c221-4e1d02ee63f7"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "Y_pred = clf.predict(X_test) \n",
        "evaluate(Y_test, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model Performance\n",
            "Accuracy = 0.96%.\n",
            "[[277   2]\n",
            " [ 13  53]]\n",
            "\n",
            "precision:\n",
            "0.9636363636363636\n",
            "\n",
            "recall:\n",
            "0.803030303030303\n",
            "\n",
            "f1:\n",
            "0.8760330578512396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9565217391304348"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}